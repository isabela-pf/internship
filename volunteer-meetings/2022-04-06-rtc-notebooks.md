# Collaborative exploration of RTC in Jupyter notebooks

## Meeting Agenda

- JupyterLab environment with RTC, extensions such as video chat (binder and jitsi chat extension)
- Compare actions from previous audits
- What kind of information do you think will help you build more accessible RTC tools?
- What tasks do you commonly do in a notebook? Which of these tasks do you want to collaborate on or how?

### Isabela notes

Expectations/what is wanted
- are rtc and accessibility simpatico?
- we still live in an ableist society
- how do we set something up where an abled and disabled person can collaborate in real time together.
- Wants a disabled person’s feedback in the report. That would be the main goal. That’s the only way it can be taken seriously.
     - How do we make this happen?
     - It’s a struggle because we work in a place where this isn’t inclusive
     - Not going with 
- What do disabled people lose (potentially) from our solutions? A good way to review design?
- Physical analogies for non-physical places
     - sign language interpretation as rtc
    - how do you design this for low bandwidth

Isabela had to switch meetings, so she has no notes for the middle.

- Opportunity for people to put together a work that couldn’t have existed otherwise
- Introspecting the design process
    - How insufficient the design process is to help abled people understand what is needed
     - We do not have the resources to make accessible scientific computing now
- “Accessibility and the search for the perfect notebook”
- What is RTC (scope)?
- Discussion about the absence issue. Maybe noting the absence is the most helpful thing we can do.
